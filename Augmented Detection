!pip install opencv-python-headless
import os
import json
import cv2
import argparse
from tqdm import tqdm
import shutil
from shapely.geometry import Point
from shapely.geometry.polygon import Polygon
from google.colab.patches import cv2_imshow # Import cv2_imshow from google.colab.patches

def poly2bbox(poly_coord):
    x_coords = [coord[0] for coord in poly_coord]
    y_coords = [coord[1] for coord in poly_coord]
    x_min = min(x_coords)
    x_max = max(x_coords)
    y_min = min(y_coords)
    y_max = max(y_coords)
    return [[x_min, y_min], [x_max, y_max]]

def create_txt_file(input_directory):
    train_files = os.listdir(os.path.join(input_directory, 'images', 'train'))
    val_files = os.listdir(os.path.join(input_directory, 'images', 'val'))
    train_files.sort()
    val_files.sort()

    with open(os.path.join(input_directory, 'train.txt'), 'w') as f:
        for filename in train_files:
            f.write(filename.split('.')[0] + '\n')

    with open(os.path.join(input_directory, 'test.txt'), 'w') as f:
        for filename in val_files:
            f.write(filename.split('.')[0] + '\n')

def is_point_inside_polygon(points, poly):
    poly = Polygon(poly)
    x_coords = [point[0] for point in points]
    y_coords = [point[1] for point in points]
    centroid = (sum(x_coords) / len(points), sum(y_coords) / len(points))
    inside = poly.contains(Point(centroid))
    return inside

def create_yolo_bbox_string(class_id, bbox, img_width, img_height):
    x_center = (bbox[0][0] + bbox[1][0]) / (2 * img_width)
    y_center = (bbox[0][1] + bbox[1][1]) / (2 * img_height)
    width = (bbox[1][0] - bbox[0][0]) / img_width
    height = (bbox[1][1] - bbox[0][1]) / img_height
    return f'{class_id} {x_center} {y_center} {width} {height}'

def visualize_annotations(img, annotations, class_names):
    for annotation in annotations:
        class_id = annotation['class_id']
        bbox = annotation['bbox']
        x1, y1 = bbox[0]
        x2, y2 = bbox[1]
        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
        label = f'{class_names[class_id]}: {class_id}'
        cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

def transform_dataset(input_directory, lp_size, ocr_size, visualize=False, visualize_limit=10):
    input_directory = os.path.normpath(input_directory)
    train_txt_path = os.path.join(input_directory, 'UC3M-LP/train.txt')
    test_txt_path = os.path.join(input_directory, 'UC3M-LP/test.txt')

    for path in [train_txt_path, test_txt_path]:
        if not os.path.isfile(path):
            raise FileNotFoundError(f"\n[ERROR] Missing file: {path}\nEnsure the input_directory directly contains 'train.txt' and 'test.txt'.\n")

    last_dir = os.path.basename(input_directory.rstrip('/\\'))
    lp_directory = os.path.join(os.path.dirname(input_directory), last_dir, 'LP')
    ocr_directory = os.path.join(os.path.dirname(input_directory), last_dir, 'OCR')

    for directory in [lp_directory, ocr_directory]:
        for subfolder in ['images/train', 'images/val', 'labels/train', 'labels/val']:
            os.makedirs(os.path.join(directory, subfolder), exist_ok=True)

    ocr_classes = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
    visualization_counter = 0

    for txt_file in [train_txt_path, test_txt_path]:
        split = 'train' if 'train' in txt_file else 'test'
        yolo_split = 'train' if 'train' in txt_file else 'val'

        with open(txt_file, 'r') as f:
            filenames = f.read().splitlines()

        print(f'[INFO] Processing {split} split ({len(filenames)} files)')
        for filename in tqdm(filenames):
            img_path = os.path.join(input_directory, 'UC3M-LP', split, filename + '.jpg')
            json_path = os.path.join(input_directory, 'UC3M-LP', split, filename + '.json')

            if not os.path.isfile(img_path):
                print(f'[WARNING] Image file not found: {img_path}. Skipping...')
                continue
            if not os.path.isfile(json_path):
                print(f'[WARNING] JSON label not found: {json_path}. Skipping...')
                continue

            img = cv2.imread(img_path)
            if img is None:
                print(f'[WARNING] Failed to load image: {img_path}. Skipping...')
                continue
            img_height, img_width, _ = img.shape

            with open(json_path, 'r') as f:
                data = json.load(f)

            for lp_data in data.get('lps', []):
                lp_img = img.copy()
                lp_id = lp_data['lp_id']
                poly_coord = lp_data['poly_coord']
                lp_bbox = poly2bbox(poly_coord)

                lp_output_path = os.path.join(lp_directory, 'images', yolo_split, f'{filename}.jpg')
                if not os.path.exists(lp_output_path):
                    rescale_factor_lp = lp_size / max(img_height, img_width)
                    lp_img_resized = cv2.resize(lp_img, (
                        int(img_width * rescale_factor_lp),
                        int(img_height * rescale_factor_lp)
                    ))
                    cv2.imwrite(lp_output_path, lp_img_resized)

                lp_yolo_path = os.path.join(lp_directory, 'labels', yolo_split, f'{filename}.txt')
                with open(lp_yolo_path, 'a' if os.path.exists(lp_yolo_path) else 'w') as lp_f:
                    lp_f.write(create_yolo_bbox_string(0, lp_bbox, img_width, img_height) + '\n')

                x1, y1 = lp_bbox[0]
                x2, y2 = lp_bbox[1]
                ocr_img = lp_img[y1:y2, x1:x2]
                ocr_img_offset_x, ocr_img_offset_y = x1, y1

                if ocr_img.size == 0:
                    print(f'[WARNING] OCR image crop failed: {filename}_{lp_id}. Skipping...')
                    continue

                ocr_height, ocr_width, _ = ocr_img.shape
                rescale_factor_ocr = ocr_size / max(ocr_height, ocr_width)
                ocr_img_resized = cv2.resize(ocr_img, (
                    int(ocr_width * rescale_factor_ocr),
                    int(ocr_height * rescale_factor_ocr)
                ))

                ocr_output_path = os.path.join(ocr_directory, 'images', yolo_split, f'{filename}_{lp_id}.jpg')
                cv2.imwrite(ocr_output_path, ocr_img_resized)

                ocr_yolo_path = os.path.join(ocr_directory, 'labels', yolo_split, f'{filename}_{lp_id}.txt')
                with open(ocr_yolo_path, 'a' if os.path.exists(ocr_yolo_path) else 'w') as ocr_f:
                    for char_data in lp_data.get('characters', []):
                        char_id = char_data['char_id']
                        if char_id not in ocr_classes:
                            print(f'[WARNING] Unknown character "{char_id}" in {filename}. Skipping...')
                            continue
                        class_id = ocr_classes.index(char_id)
                        bbox = char_data['bbox_coord']
                        bbox = [
                            [bbox[0][0] - ocr_img_offset_x, bbox[0][1] - ocr_img_offset_y],
                            [bbox[1][0] - ocr_img_offset_x, bbox[1][1] - ocr_img_offset_y]
                        ]
                        ocr_f.write(create_yolo_bbox_string(class_id, bbox, ocr_width, ocr_height) + '\n')

                if visualize and visualization_counter < visualize_limit:
                    lp_annotations = [{'class_id': 0, 'bbox': lp_bbox}]
                    ocr_annotations = []
                    for char_data in lp_data.get('characters', []):
                        char_id = char_data['char_id']
                        if char_id not in ocr_classes:
                            continue
                        class_id = ocr_classes.index(char_id)
                        bbox = char_data['bbox_coord']
                        bbox = [
                            [bbox[0][0] - ocr_img_offset_x, bbox[0][1] - ocr_img_offset_y],
                            [bbox[1][0] - ocr_img_offset_x, bbox[1][1] - ocr_img_offset_y]
                        ]
                        ocr_annotations.append({'class_id': class_id, 'bbox': bbox})

                    visualize_annotations(lp_img, lp_annotations, ['License Plate'])
                    visualize_annotations(ocr_img, ocr_annotations, list('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'))

                    cv2_imshow(lp_img) # Use cv2_imshow instead of cv2.imshow
                    cv2_imshow(ocr_img) # Use cv2_imshow instead of cv2.imshow
                    visualization_counter += 1

    print('[INFO] Creating dataset YAML files for YOLO training...')
    create_txt_file(lp_directory)
    create_txt_file(ocr_directory)
    print('[INFO] Transformation complete')

# === Run Script ===
input_directory = '/content/UC3M'  # Replace this with your actual path
lp_size = 640
ocr_size = 320
visualize = True
visualize_limit = 10

transform_dataset(input_directory, lp_size, ocr_size, visualize=visualize, visualize_limit=visualize_limit)
